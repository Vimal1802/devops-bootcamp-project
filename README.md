# DevOps Bootcamp Project  
Automated Infrastructure Deployment using Terraform, AWS, Ansible, and GitHub Actions

## ðŸ“Œ Overview
This project provisions cloud infrastructure using Terraform, configures servers using Ansible, and deploys applications through a GitHub Actions CI/CD pipeline. Follow the steps below to deploy and manage the environment endâ€‘toâ€‘end.

## Architecture Diagram

<img width="938" height="785" alt="Screenshot 2026-01-16 230922" src="https://github.com/user-attachments/assets/57efecf2-f980-4367-9de7-ce217dda8eb2" />

## ðŸ§° Prerequisites
- Terraform installed locally
- AWS account with required IAM permissions
- GitHub repository forked or cloned
- SSM Session Manager access to connect to the Ansible controller
- Basic knowledge of Ansible and EC2

# ðŸš€ Deployment Steps

## ðŸ“¥ 1. Clone the Repository
```bash
git clone https://github.com/Vimal1802/devops-bootcamp-project.git && cd devops-bootcamp-project
```

### ðŸ“¤1.1 Push the Repository to Your Own GitHub Account

Because **GitHub Actions** workflows run exclusively on GitHub and not on local machines, you must push the cloned project to your own GitHub repository before the workflow can execute.

```bash
 git remote remove origin
 ```
 ```bash
 git remote add origin https://github.com/<your-username>/<your-repo>.git
 ```
 ```bash
 git push -u origin main
 ```

### ðŸ“¤1.2 Add Required GitHub Secrets (Required for CI/CD)

After instrastructure deployment and before running the pipeline, configure these secrets in:

- Go to **GitHub.com**
 - Open Your Repository
 - Click **Settings**
 - Select **Secrets and Variables**
 - Click **Actions**
 - Add the required secrets:
   - **AWS_ACCOUNT_ID** : (Your 12â€‘digit AWS account number)
   - **AWS_REGION** : (Region used for deployments (e.g., ap-southeast-1))
   - **INSTANCE_ID** : (Ansible Controller Instance ID)

> **Reminder:** *This section is to be completed only upon the completion of SectionÂ 2.0.*

## ðŸ—ï¸ 2. Deploy Infrastructure with Terraform

### ðŸ—ï¸ 2.1 Configure AWS Credentials (Required Before Using Terraform)

Where to get the AWS credentials

 - Log in to the AWS Console
 - Go to **IAM**
 - Click **Users**
 - Select your **IAM user**
 - Open the **Security Credentials** tab
 - Scroll down to **Access Keys**
 - Create or copy your **Access Key ID** and **Secret Access Key**

Once you have your **Access Key ID** and **Secret Access Key**, proceed to the next section to configure AWS on your machine so you can run Terraform commands for the deployment.

 **Run this command in your local terminal:**
```bash
aws configure
```

You will be prompted to enter the following:

 - AWS Access Key ID : `This is the public part of your AWS access credentials.`
 - AWS Secret Access Key : `This is the private part â€” keep it secure and never share it.`
 - Default region name (Example): `ap-southeast-1`
 - Default output format : `You can simply press Enter to skip this (usually defaults to JSON).`

### ðŸ—ï¸ 2.2 Deploy Infrastructure with Terraform

**Go into the Terraform folder**

You need to run all Terraform commands from inside the terraform directory:
```bash
cd terraform
```
**Set up Terraform for the first time**

This command downloads the required Terraform plugins:
```bash
terraform init
```
**Check what Terraform will create**

This provides a preview of the resources Terraform will create, without making any changes since it is only a dry run:
```bash
terraform plan
```
**Deploy your infrastructure**

This command actually builds everything in your AWS account:
```bash
terraform apply --auto-approve
```
**Enable Remote State (after deployment completes)**

Once the infrastructure has successfully deployed:

 - Open the `main.tf` file in the Terraform folder.
 - Find the section labeled `REMOTE STATE MANAGEMENT`
 - Uncomment only the backend block (remove the **#** symbols from the Terraform block, not the heading or description).

 - Save the file.

Then run the following command to update the state:
```bash
terraform init -migrate-state -force-copy
```

## ðŸ–¥ï¸ 3. Access the Ansible Controller
 - Log in to the **AWS Management Console**
 - Go to the **EC2** service
 - In the instance list, locate and select **Ansible Controller**
 - Click **Connect** at the top right
 - Choose **Session Manager**
 - Click **Connect**

## âš™ï¸ 4. Configure Ansible Environment

### âš™ï¸4.1 Switch to Ubuntu and Open the Ansible Folder

To access the Ansible working directory, switch to the `ubuntu` user and navigate into the `ansible` folder:

```bash
sudo su - ubuntu -c "cd ansible && bash"
```

> **Note:** *If the directory is missing, the initial setup through `user data` is likely still in progress. It may take a few minutes to install dependencies and move the Ansible configuration. Monitor progress with: `cat /home/ubuntu/deploy.log`*


### âš™ï¸4.2 Update the Ansible Inventory

This step is done after switching to the `ubuntu` user and navigating into the ansible directory using `cd ansible`

```bash
nano inventory.ini
```

- **Instructions**: After opening the file , navigate using your arrow keys and replace the ansible_host section with your actual **Web Server** , **Monitoring Server** Instance IDs and also bucket name with your **S3 Bucket Name**

- **To Save**: Press `Ctrl + O` then `Enter`.
- **To Exit**: Press `Ctrl + X`.

### âš™ï¸4.3 Update the Ansible Playbook
```bash
nano web-server.yml
```
- **Instructions**: After opening the file , navigate using your arrow keys and replace the placeholders with your **ECR repository URL**
- **To Save**: Press `Ctrl + O` then `Enter`.
- **To Exit**: Press `Ctrl + X`.


### âš™ï¸4.4 Test Connectivity
```bash
ansible all -m ping
```

### âš™ï¸4.5 Install Dependencies
```bash
ansible-galaxy install -r requirements.yml
```

> **Reminder:** *Revisit Section 1.2 and complete it before progressing to the next section.*

## ðŸš€ 5. Run the CI/CD Pipeline in GitHub Actions to deploy the  Web Server

### Initiate the Deployment
Trigger the automated CI/CD pipeline to build your Docker image and deploy it to AWS EC2 via SSM ( `web-server.yml` ansible playbook):



- Navigate to your **GitHub Repository** and click on the **Actions** tab.

- In the left sidebar, select the **Build and Deploy** workflow.

- Click the **Run workflow** dropdown menu on the right.

- Ensure the **Main** branch is selected and click the green **Run workflow** button.

### Verify the Deployment
Once the workflow finishes, verify the results in the logs:

- Navigate to **Actions** â†’ Click on the **Latest Run.**

- Select the **deploy** job from the sidebar.

- Expand the **Trigger Deployment via SSM** step to view the Ansible output.

- Confirm the following:

  - Status: The `web_server` should show **ok** or **changed.**

  - Failures: Ensure the `failed` count is `0`.

> **Note**: *This pipeline has two main steps. First, the **Build** step creates a Docker image of your application and uploads it to Amazon ECR. Then, the **Deploy** step uses the Ansible Controller (through AWS SSM) to run the `web-server.yml` playbook which pulls the newest image, and redeploy the web server. You can watch both steps happen in real time on the GitHub Actions page, and the full workflow is located in `.github/workflows/deploy.yml.`*

## ðŸŒ 6. DNS and TLS Management (Cloudflare)
To make your application accessible via your domain, follow these steps:

### ðŸŒ 6.1. DNS Configuration
- Log in to your **Cloudflare Dashboard** and select your domain.
- Navigate to **DNS > Records** and click **Add Record**.
- Create an **A Record**:
   - **Name**: `web` (creates `web.yourdomain.com`)
   - **IPv4 address**: Your **Web Server Public IP**.
   - **Proxy status**: **Proxied** (Orange cloud enabled).

### ðŸŒ 6.2. SSL/TLS Encryption
- Navigate to **SSL/TLS > Overview**.
- Click **Configure** and set the encryption mode to **Flexible**.
   *(This secures the connection between the user and Cloudflare while the origin server uses port 80).*
- Click **Save**

### ðŸŒ 6.2 Verification and Connectivity Testing

```bash
https://web.your-domain.com/
```

## ðŸ“¡ 7.0 Deploy the Monitoring Server With a Private Cloudflare Tunnel

This step sets up your full monitoring system **Prometheus**, **Grafana**, and supporting components and securely exposes the **Grafana** dashboard to the internet using a private **Cloudflare Tunnel**. This means you can access your monitoring dashboard through your own domain **without opening any ports** on your EC2 instance, keeping everything secure while still being easy to reach.

### ðŸ“¡ 7.1 Update the Grafana Domain in monitoring-server.yml

Before running the `monitoring-server.yml` playbook, you must update the **Grafana** domain settings with your own domain. This ensures **Grafana** works correctly with **Cloudflare Tunnel** and loads properly under your custom URL.

**Edit the Monitoring-Server.yml ansible playbook**

Before editing the `monitoring-server.yml` file, make sure you are inside the `ansible` directory on the **Ansible Controller**.

```bash
nano monitoring-server.yml
```

**Locate the `grafana_ini` Section**

```bash
vars:
  grafana_ini:
    security:
      admin_user: "admin"
      admin_password: "admin"
    server:
      domain: "monitoring.yourdomain.com"
      root_url: "https://monitoring.yourdomain.com"
      http_port: 3000
```

**Update Both Domain Fields**

Replace both values with your own monitoring domain.

```bash
domain: "monitoring.yourdomain.com"
root_url: "https://monitoring.yourdomain.com"
```

- **To Save**: Press `Ctrl + O` then `Enter`.
- **To Exit**: Press `Ctrl + X`.

### ðŸ“¡ 7.2 Deploy the Monitoring Server Using the Cloudflare Token

The monitoring playbook requires a **Cloudflare Tunnel token** so it can authenticate and start the secure tunnel container. This token must be supplied manually when you run the playbook.

**Get Your Cloudflare Tunnel Token**


You can obtain the token from your Cloudflare dashboard:

 - Log in to **Cloudflare**
 - Go to **Zero Trust**
 - Select **Networks** â†’ **Connectors** â†’ **Cloudflare Tunnels**
 - Select **Add a Tunnel** â†’ **Cloudflared** â†’ **Tunnel Name : `Monitoring Server`** â†’ **Save Tunnel**
 - Select **Docker** â†’ Copy the `--token cloudflare` (keep this aside for later) â†’ **Next** 
> **Note:** *The `monitoring-server.yml` playbook is already "pre-programmed" with the Cloudflare docker image and the exact settings needed to run. Because these technical details are already built into the file, your only job is to only copy the Token*
 - Route Traffic â†’ **Published applications**

    - Hostname : 
      - **Subdomain** : `monitoring` , **Domain** : `yourdomain.com`
    - Service : 
      - **Type** : `HTTP` , **URL** : `localhost : 3000`
 - Click **Complete Setup**

**Deploy the Monitoring Server With the Token**

```bash
ansible-playbook monitoring-server.yml -e "cloudflare_token=abc123xyz987-long-token-value"
```

**Access the Grafana Dashboard**

After the deployment completes, open your browser and go to your monitoring domain  to access the Grafana dashboard.

```bash
https://monitoring.yourdomain.com
```


> **Note**: *You do not need to manually create a DNS or CNAME record in Cloudflare for your monitoring domain. Because this playbook uses a **Cloudflare Tunnel token**, Cloudflare **automatically creates and manages** the required CNAME record when the tunnel starts, so your monitoring domain (e.g., monitoring.yourdomain.com) will point to the correct tunnel endpoint **without any additional setup**.*

### ðŸ“¡ 7.3 Configure Grafana to monitor the Web Server

**Log In to Grafana**

Open your monitoring URL in your browser

```bash
https://monitoring.yourdomain.com
```

Log in with the default Grafana credentials

 - **Username:** admin
 - **Password:** admin

Grafana will ask you to change the password â€” update it for security.

**Add Prometheus as a Data Source**

Grafana needs to know where Prometheus is running so it can query your Node Exporter metrics.

 - In Grafanaâ€™s left sidebar, click **Connections** â†’ **Data Sources**
 - Click **Add data source**
 - Select **Prometheus**
 - Under HTTP URL, enter: `http://localhost:9090`
 - Scroll down and click **Save & Test**
 - You should see: `Successfully queried the Prometheus API.`

**Confirm That Node Exporter Metrics Are Being Collected**

You can confirm Node Exporter is working by querying Prometheus through Grafana.

 - In the left sidebar, click **Explore**
 - Select your Prometheus data source
 - Enter a test query:-
   - **CPU Usage Metrics** : `node_cpu_seconds_total`
   - **Memory Usage Metrics** : `node_memory_MemAvailable_bytes`
   - **Disk Usage Metrics** : `node_filesystem_avail_bytes`
 - You should see timeâ€‘series results â€” this confirms Prometheus is scraping your server.

**Import the Node Exporter Dashboards**

 - In Grafana on the top right , click + (Create) â†’ Import Dashboard
 - In the `Find and Import Dashboard` field, enter dashboard ID: `1860`
 - Click **Load**
 - Name : `Web Server Monitoring`
 - Click **Import**

**Verify That Prometheus Is Scraping the Web Server**

 - Click the **Explore** icon in the left sidebar.
 - Ensure the data source is set to **Prometheus**.
 - In the query box, type: **up** and click **Run Query**.
 - Look at the results:
   - You should see an entry for job=`web_server_node`.
   - If the value is `1`, the server is `UP` and scraping correctly.
   - If the value is `0`, Prometheus can see the server, but the Node Exporter is down.


### ðŸ“¡ 7.4 Create CPU, Memory, and Disk Usage Visualizations in the Node Exporter Dashboard

After importing the Node Exporter dashboard (`ID: 1860`), you can customize the homepage by adding your own CPU, Memory, and Disk Usage panels. These visualizations will appear at the top of the dashboard so you can easily monitor the Web Serverâ€™s performance.

**Open the Node Exporter Dashboard**

 - In Grafanaâ€™s left sidebar, click Dashboards
 - Open **Web Server Monitoring**

**Enter Edit Mode**

 - Click the **Edit** In the top-right toolbar
 - Drag CPU, Memory, and Disk panels to the **top rows**
 - Resize them as needed
 - Click **Save Dashboard**

This keeps the existing panels but makes the important ones easier to find.
