# DevOps Bootcamp Project  
Automated Infrastructure Deployment using Terraform, AWS, Ansible, and GitHub Actions

## üìå Overview
This project provisions cloud infrastructure using Terraform, configures servers using Ansible, and deploys applications through a GitHub Actions CI/CD pipeline. Follow the steps below to deploy and manage the environment end‚Äëto‚Äëend.

## Architecture Diagram

<img width="938" height="785" alt="Screenshot 2026-01-16 230922" src="https://github.com/user-attachments/assets/57efecf2-f980-4367-9de7-ce217dda8eb2" />

## üß∞ Prerequisites
- Terraform installed locally
- AWS account with required IAM permissions
- GitHub repository forked or cloned
- SSM Session Manager access to connect to the Ansible controller
- Basic knowledge of Ansible and EC2

# üöÄ Deployment Steps

## üì• 1. Cloning the Repository via GitHub
To use this project, you need to download the code to your computer and then "re-upload" it to your own GitHub account. This ensures you have full control over the GitHub Actions automation.

### üì• 1.1 Clone the Template

```bash
git clone https://github.com/Vimal1802/devops-bootcamp-project.git && cd devops-bootcamp-project
```

### üì• 1.2 Transfer to YOUR GitHub Account

**Create a new Repo**: Go to GitHub.new and create a repository named `devops-bootcamp-project`. (Leave it empty‚Äîdo not add a README or License).

**Disconnect from Source**: Remove the link to my original repository
```bash
git remote remove origin
```

**Connect to Your Repo**: Link it to your new personal repository
```bash
git remote add origin https://github.com/<your-username>/devops-bootcamp-project.git
```

**Upload the Code**: Push the files to your account
```bash
git push -u origin main
```

### üì§1.3 Add Required GitHub Secrets (Required for CI/CD)

Provision GitHub Actions repository secrets for the AWS Account ID and deployment region:

- Go to **GitHub.com**
 - Open Your Repository
 - Click **Settings**
 - Select **Secrets and Variables**
 - Click **Actions**
 - Add the repository secrets:
   - **AWS_ACCOUNT_ID** : (Your 12‚Äëdigit AWS account number)
   - **AWS_REGION** : (Region used for deployments (e.g., ap-southeast-1))

## üèóÔ∏è 2. Deploy Infrastructure with Terraform

### üèóÔ∏è 2.1 Configure AWS Credentials (Required Before Using Terraform)

Where to get the AWS credentials

 - Log in to the AWS Console
 - Go to **IAM**
 - Click **Users**
 - Select your **IAM user**
 - Open the **Security Credentials** tab
 - Scroll down to **Access Keys**
 - Create or copy your **Access Key ID** and **Secret Access Key**

Once you have your **Access Key ID** and **Secret Access Key**, proceed to the next section to configure AWS on your machine so you can run Terraform commands for the deployment.

 **Run this command in your local terminal:**
```bash
aws configure
```

You will be prompted to enter the following:

 - AWS Access Key ID : `This is the public part of your AWS access credentials.`
 - AWS Secret Access Key : `This is the private part ‚Äî keep it secure and never share it.`
 - Default region name (Example): `ap-southeast-1`
 - Default output format : `You can simply press Enter to skip this (usually defaults to JSON).`

### üèóÔ∏è 2.2 Deploy Infrastructure with Terraform

**Go into the Terraform folder**

You need to run all Terraform commands from inside the terraform directory:
```bash
cd terraform
```
**Set up Terraform for the first time**

This command downloads the required Terraform plugins:
```bash
terraform init
```
**Check what Terraform will create**

This provides a preview of the resources Terraform will create, without making any changes since it is only a dry run:
```bash
terraform plan
```
**Deploy your infrastructure**

This command actually builds everything in your AWS account:
```bash
terraform apply --auto-approve
```
**Enable Remote State (after deployment completes)**

Once the infrastructure has successfully deployed:

 - Open the `main.tf` file in the Terraform folder.
 - Find the section labeled `REMOTE STATE MANAGEMENT`
 - Uncomment only the backend block (remove the **#** symbols from the Terraform block, not the heading or description).

 - Save the file.

Then run the following command to update the state:
```bash
terraform init -migrate-state -force-copy
```

## üñ•Ô∏è 3. Access the Ansible Controller
 - Log in to the **AWS Management Console**
 - Go to the **EC2** service
 - In the instance list, locate and select **Ansible Controller**
 - Click **Connect** at the top right
 - Choose **Session Manager**
 - Click **Connect**

## ‚öôÔ∏è 4. Configure Ansible Environment

### ‚öôÔ∏è4.1 Switch to Ubuntu and Open the Ansible Folder

To access the Ansible working directory, switch to the `ubuntu` user and navigate into the `ansible` folder:

```bash
sudo su - ubuntu -c "cd ansible && bash"
```

> **Note:** *If the directory is missing, the initial setup through `user data` is likely still in progress. It may take a few minutes to install dependencies and move the Ansible configuration. Monitor progress with: `cat /home/ubuntu/deploy.log`*


### ‚öôÔ∏è4.2 Update the Ansible Inventory

This step is done after switching to the `ubuntu` user and navigating into the ansible directory using `cd ansible`

```bash
nano inventory.ini
```

- **Instructions**: After opening the file , navigate using your arrow keys and replace the ansible_host section with your actual **Web Server** , **Monitoring Server** Instance IDs and also bucket name with your **S3 Bucket Name**

- **To Save**: Press `Ctrl + O` then `Enter`.
- **To Exit**: Press `Ctrl + X`.

### ‚öôÔ∏è4.3 Update the Ansible Playbook (Web Server)
```bash
nano web-server.yml
```
**Locate the `vars` Section**

```bash
vars:
  # #1. ECR CONFIGURATION
  # Ensure these match your ECR outputs from Terraform
  ecr_registry: "update-ecr-url.dkr.ecr.ap-southeast-1.amazonaws.com"
  ecr_url: "{{ ecr_registry }}/devops-bootcamp/final-project-vimaldeep"
    
  # #2. DEPLOYMENT PATHS
  app_path: "/home/ubuntu"
  raw_compose_url: "https://raw.githubusercontent.com/<your-username>/devops-bootcamp-project/main/app/docker-compose.yml"
```

**Update `ecr_registry` and `raw_compose_url` fields**

- **To Save**: Press `Ctrl + O` then `Enter`.
- **To Exit**: Press `Ctrl + X`.

> **Note:** *This configuration is only required once and during the initial setup.*


### ‚öôÔ∏è4.4 Test Connectivity
```bash
ansible all -m ping
```

### ‚öôÔ∏è4.5 Install Dependencies
```bash
ansible-galaxy install -r requirements.yml
```

## üöÄ 5. Run the CI/CD Pipeline in GitHub Actions to deploy the Web Application

### Initiate the Deployment
Trigger the automated CI/CD pipeline to build your Docker image and deploy it to AWS EC2 via SSM ( `web-server.yml` ansible playbook):

- Navigate to your **GitHub Repository** and click on the **Actions** tab.

- Click the **Enable Actions on this repository** (You may skip this if you have already enabled it)

- In the left sidebar, select the **Build and Deploy** workflow.

- Click the **Run workflow** dropdown menu on the right.

- Ensure the **Main** branch is selected and click the green **Run workflow** button.

### Verify the Deployment
Once the workflow finishes, verify the results in the action section:

- Navigate to **Actions** ‚Üí Click on the **Latest Run.**

- Select the **deploy** job from the sidebar and ensure it is **successful.**

- For more info on the deployment and troubleshooting you may use the **Systems Manager** feature in **AWS console**

  - Log in to your **AWS Management Console**
  - In the top search bar, type "**SSM**" or "**Systems Manager**" and select the service.
  - On the left-hand sidebar, scroll down to **Node Tools** section and click on **Run Command**.
  - Once inside the Run Command dashboard, click on the **Command history** tab
  - Click on the latest **Command ID** with the comment "Triggering Ansible Deployment"
  - Click on the **instance-id** and drop down the **Output** section
  - To confirm if deployment was successful , the `web_server` should show `ok` or `changed`.

> **Note**: *This pipeline has two main steps. First, the **Build** step creates a Docker image of your application and uploads it to Amazon ECR. Then, the **Deploy** step uses the Ansible Controller (through AWS SSM) to run the `web-server.yml` playbook which pulls the newest image, and redeploy the web server. You can watch both steps happen in real time on the GitHub Actions page, and the full workflow is located in `.github/workflows/deploy.yml.`*

### üöÄ 5.1 Verification and Connectivity Testing

```bash
http://web-server-public-ip
```

## üåê 6. DNS and TLS Management (Cloudflare)
To make your application accessible via your domain, follow these steps:

### üåê 6.1. DNS Configuration
- Log in to your **Cloudflare Dashboard** and select your domain.
- Navigate to **DNS > Records** and click **Add Record**.
- Create an **A Record**:
   - **Name**: `web` (creates `web.yourdomain.com`)
   - **IPv4 address**: Your **Web Server Public IP**.
   - **Proxy status**: **Proxied** (Orange cloud enabled).

### üåê 6.2. SSL/TLS Encryption
- Navigate to **SSL/TLS > Overview**.
- Click **Configure** and set the encryption mode to **Flexible**.
   *(This secures the connection between the user and Cloudflare while the origin server uses port 80).*
- Click **Save**

### üåê 6.2 Verification and Connectivity Testing

```bash
https://web.your-domain.com/
```

## üì° 7.0 Deploy the Monitoring Server With a Private Cloudflare Tunnel

This step sets up your full monitoring system **Prometheus**, **Grafana**, and supporting components and securely exposes the **Grafana** dashboard to the internet using a private **Cloudflare Tunnel**. This means you can access your monitoring dashboard through your own domain **without opening any ports** on your EC2 instance, keeping everything secure while still being easy to reach.

### üì° 7.1 Update the Grafana Domain in monitoring-server.yml

Before running the `monitoring-server.yml` playbook, you must update the **Grafana** domain settings with your own domain. This ensures **Grafana** works correctly with **Cloudflare Tunnel** and loads properly under your custom URL.

**Edit the Monitoring-Server.yml ansible playbook**

Before editing the `monitoring-server.yml` file, make sure you are inside the `ansible` directory on the **Ansible Controller**.

```bash
nano monitoring-server.yml
```

**Locate the `grafana_ini` Section**

```bash
vars:
  grafana_ini:
    security:
      admin_user: "admin"
      admin_password: "admin"
    server:
      domain: "monitoring.yourdomain.com"
      root_url: "https://monitoring.yourdomain.com"
      http_port: 3000
```

**Update Both Domain Fields**

Replace both values with your own monitoring domain.

```bash
domain: "monitoring.yourdomain.com"
root_url: "https://monitoring.yourdomain.com"
```

- **To Save**: Press `Ctrl + O` then `Enter`.
- **To Exit**: Press `Ctrl + X`.

### üì° 7.2 Deploy the Monitoring Server Using the Cloudflare Token

The monitoring playbook requires a **Cloudflare Tunnel token** so it can authenticate and start the secure tunnel container. This token must be supplied manually when you run the playbook.

**Get Your Cloudflare Tunnel Token**


You can obtain the token from your Cloudflare dashboard:

 - Log in to **Cloudflare**
 - Go to **Zero Trust**
 - Select **Networks** ‚Üí **Connectors** ‚Üí **Cloudflare Tunnels**
 - Select **Add a Tunnel** ‚Üí **Cloudflared** ‚Üí **Tunnel Name : `Monitoring Server`** ‚Üí **Save Tunnel**
 - Select **Docker** ‚Üí Copy the `--token cloudflare` (keep this aside for later) ‚Üí **Next** 
> **Note:** *The `monitoring-server.yml` playbook is already "pre-programmed" with the Cloudflare docker image and the exact settings needed to run. Because these technical details are already built into the file, your only job is to only copy the Token*
 - Route Traffic ‚Üí **Published applications**

    - Hostname : 
      - **Subdomain** : `monitoring` , **Domain** : `yourdomain.com`
    - Service : 
      - **Type** : `HTTP` , **URL** : `localhost : 3000`
 - Click **Complete Setup**

**Deploy the Monitoring Server With the Token**

```bash
ansible-playbook monitoring-server.yml -e "cloudflare_token=abc123xyz987-long-token-value"
```

**Access the Grafana Dashboard**

After the deployment completes, open your browser and go to your monitoring domain  to access the Grafana dashboard.

```bash
https://monitoring.yourdomain.com
```


> **Note**: *You do not need to manually create a DNS or CNAME record in Cloudflare for your monitoring domain. Because this playbook uses a **Cloudflare Tunnel token**, Cloudflare **automatically creates and manages** the required CNAME record when the tunnel starts, so your monitoring domain (e.g., monitoring.yourdomain.com) will point to the correct tunnel endpoint **without any additional setup**.*

### üì° 7.3 Configure Grafana to monitor the Web Server

**Log In to Grafana**

Open your monitoring URL in your browser

```bash
https://monitoring.yourdomain.com
```

Log in with the default Grafana credentials

 - **Username:** admin
 - **Password:** admin

Grafana will ask you to change the password ‚Äî update it for security.

**Add Prometheus as a Data Source**

Grafana needs to know where Prometheus is running so it can query your Node Exporter metrics.

 - In Grafana‚Äôs left sidebar, click **Connections** ‚Üí **Data Sources**
 - Click **Add data source**
 - Select **Prometheus**
 - Under HTTP URL, enter: `http://localhost:9090`
 - Scroll down and click **Save & Test**
 - You should see: `Successfully queried the Prometheus API.`

**Confirm That Node Exporter Metrics Are Being Collected**

You can confirm Node Exporter is working by querying Prometheus through Grafana.

 - In the left sidebar, click **Explore**
 - Select your Prometheus data source
 - Enter a test query:-
   - **CPU Usage Metrics** : `node_cpu_seconds_total`
   - **Memory Usage Metrics** : `node_memory_MemAvailable_bytes`
   - **Disk Usage Metrics** : `node_filesystem_avail_bytes`
 - You should see time‚Äëseries results ‚Äî this confirms Prometheus is scraping your server.

**Import the Node Exporter Dashboards**

 - In Grafana on the top right , click + (Create) ‚Üí Import Dashboard
 - In the `Find and Import Dashboard` field, enter dashboard ID: `1860`
 - Click **Load**
 - Name : `Web Server Monitoring`
 - Click **Import**

**Verify That Prometheus Is Scraping the Web Server**

 - Click the **Explore** icon in the left sidebar.
 - Ensure the data source is set to **Prometheus**.
 - In the query box, type: **up** and click **Run Query**.
 - Look at the results:
   - You should see an entry for job=`web_server_node`.
   - If the value is `1`, the server is `UP` and scraping correctly.
   - If the value is `0`, Prometheus can see the server, but the Node Exporter is down.


### üì° 7.4 Create CPU, Memory, and Disk Usage Visualizations in the Node Exporter Dashboard

After importing the Node Exporter dashboard (`ID: 1860`), you can customize the homepage by adding your own CPU, Memory, and Disk Usage panels. These visualizations will appear at the top of the dashboard so you can easily monitor the Web Server‚Äôs performance.

**Open the Node Exporter Dashboard**

 - In Grafana‚Äôs left sidebar, click Dashboards
 - Open **Web Server Monitoring**

**Enter Edit Mode**

 - Click the **Edit** In the top-right toolbar
 - Drag CPU, Memory, and Disk panels to the **top rows**
 - Resize them as needed
 - Click **Save Dashboard**

This keeps the existing panels but makes the important ones easier to find.
